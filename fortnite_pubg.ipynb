{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fortnite to Pubg\n",
    "Inspired from this [blog](https://towardsdatascience.com/turning-fortnite-into-pubg-with-deep-learning-cyclegan-2f9d339dcdb0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, Add\n",
    "from keras.layers import BatchNormalization, Activation, MaxPooling2D, Conv2DTranspose\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT = \"checkpoint/\"\n",
    "SAVED_IMAGES_PATH = \"saved_images/\"\n",
    "LOG_PATH = \"checkpoint/log.txt\"\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Saves Model in every N minutes\n",
    "TIME_INTERVALS = 20 \n",
    "\n",
    "# Show Summary of Models\n",
    "SHOW_SUMMARY = True\n",
    "\n",
    "# Learning rate of Generator and Discriminator\n",
    "DISCRIMINATOR_LR_RATE = 0.0002\n",
    "GENERATOR_LR_RATE = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Image Dimensions\n",
    "IMAGE_ROWS = 256\n",
    "IMAGE_COLS = 256\n",
    "IMAGE_CHANNELS = 3\n",
    "IMAGE_SHAPE = (IMAGE_ROWS, IMAGE_COLS, IMAGE_CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import Data\n",
    "data = Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Discriminator\n",
    "#### We are going to build [PatchGAN](https://image.slidesharecdn.com/07-image-to-imagetranslationwithconditionaladversarialnetworks-161125155412/95/imagetoimage-translation-with-conditional-adversarial-nets-upc-reading-group-24-638.jpg?cb=1480089468) Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_layers = 3 # discriminator size\n",
    "d_filter_size = 64 # filter size of first layer\n",
    "d_dropout = 0.4\n",
    "d_loss = 'mse' # mean squared error\n",
    "d_optimizer = Adam(DISCRIMINATOR_LR_RATE, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate output shape of D (PatchGAN)\n",
    "patch = int(IMAGE_ROWS / 2**(d_layers))\n",
    "patch = (patch, patch, 1)\n",
    "print(\"Patch shape: \", patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_d_layer(layer_input, filters, f_size=4, strides =2, normalization=True, dropout_rate=d_dropout):\n",
    "    d = Conv2D(filters, kernel_size=f_size, strides=strides, padding='same')(layer_input)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    if dropout_rate:\n",
    "        d = Dropout(dropout_rate)(d)\n",
    "    if normalization:\n",
    "        d = InstanceNormalization()(d)\n",
    "    return d\n",
    "    \n",
    "    \n",
    "def build_discriminator():\n",
    "    image = Input(shape=IMAGE_SHAPE)\n",
    "    layers  = []\n",
    "    \n",
    "    # Making  N (d_layers) Layers \n",
    "    for i in range(d_layers):\n",
    "        filter_size = d_filter_size * (2 ** i)\n",
    "        if not i:\n",
    "            layer = build_d_layer(image, filter_size, normalization=False)\n",
    "        else:\n",
    "            layer = build_d_layer(layers[-1], filter_size)\n",
    "            \n",
    "        layers.append(layer)\n",
    "    layers.append(layer)    \n",
    "    \n",
    "    confidence = Conv2D(1, kernel_size=4, strides=1,activation='sigmoid', padding='same')(layers[-1])\n",
    "    \n",
    "    # Model(input, output)\n",
    "    return Model(image, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator Initialization\n",
    "DCRM_A = build_discriminator()\n",
    "DCRM_B = build_discriminator()\n",
    "\n",
    "# Compile the Discriminator Model\n",
    "DCRM_A.compile(loss=d_loss, optimizer=d_optimizer, metrics=['accuracy'])\n",
    "DCRM_B.compile(loss=d_loss, optimizer=d_optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Show Summary\n",
    "if SHOW_SUMMARY:\n",
    "    print('Summary DCRM_A:')\n",
    "    DCRM_A.summary()\n",
    "    print('Summary DCRM_B:')\n",
    "    DCRM_B.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Generator\n",
    "#### We are going to build a [U-Net ](https://cdn-images-1.medium.com/max/953/1*Z98NhzbVISHa4CoemZS4Kw.png) Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_filter_size = 64 # filter size of first layer\n",
    "g_dropout = 0.2\n",
    "dropout = 0.25\n",
    "g_optimizer = Adam(GENERATOR_LR_RATE, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv2d(layer_input, filters, strides=2, f_size=4):\n",
    "    g = Conv2D(filters, kernel_size=f_size, strides=strides, padding='same')(layer_input)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    g = InstanceNormalization()(g)\n",
    "    return g\n",
    "\n",
    "\n",
    "def build_deconv2d(layer_input, skip_input, filters, strides=2, f_size=4, dropout_rate=g_dropout):\n",
    "    g = Conv2DTranspose(filters, kernel_size=f_size, strides=strides, padding='same')(layer_input)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    if dropout_rate:\n",
    "        g = Dropout(dropout_rate)(g)\n",
    "    g = InstanceNormalization()(g)\n",
    "    g = Concatenate()([g, skip_input])\n",
    "    return g\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "    image = Input(shape=IMAGE_SHAPE)\n",
    "    layers = []\n",
    "    \n",
    "    #  DownSampling the layers\n",
    "    conv1 = build_conv2d(image, g_filter_size)\n",
    "    conv2 = build_conv2d(conv1, g_filter_size*2)\n",
    "    conv3 = build_conv2d(conv2, g_filter_size*4)\n",
    "    conv4 = build_conv2d(conv3, g_filter_size*8)\n",
    "    conv5 = build_conv2d(conv4, g_filter_size*16)\n",
    "    \n",
    "    # UpSampling the Layers\n",
    "    deconv1 = build_deconv2d(conv5, conv4, g_filter_size*8)\n",
    "    deconv2 = build_deconv2d(deconv1, conv3, g_filter_size*4)\n",
    "    deconv3 = build_deconv2d(deconv2, conv2, g_filter_size*2)\n",
    "    deconv4 = build_deconv2d(deconv3, conv1, g_filter_size)\n",
    "    deconv5 = UpSampling2D(size=2)(deconv4)\n",
    "    \n",
    "    generated_image = Conv2D(IMAGE_CHANNELS, kernel_size=4, strides=1, padding='same', activation='tanh')(deconv5)\n",
    "    \n",
    "    return Model(image, generated_image)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Initialization\n",
    "GEN_AB = build_generator()\n",
    "GEN_BA = build_generator()\n",
    "\n",
    "# Generator input PlaceHolder\n",
    "IMG_A = Input(shape=IMAGE_SHAPE)\n",
    "IMG_B = Input(shape=IMAGE_SHAPE)\n",
    "\n",
    "# Generator Summary\n",
    "if SHOW_SUMMARY:\n",
    "    print('GEN_AB')\n",
    "    GEN_AB.summary()\n",
    "    print('GEN_BA')\n",
    "    GEN_BA.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adverserial Net (Combined Network) CYCLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare fake images from Generator\n",
    "FAKE_IMG_A = GEN_BA(IMG_B)\n",
    "FAKE_IMG_B = GEN_AB(IMG_A)\n",
    "\n",
    "# Reconstruct fake images back to original\n",
    "RECONSTRUCT_A = GEN_BA(FAKE_IMG_B)\n",
    "RECONSTRUCT_B = GEN_AB(FAKE_IMG_A)\n",
    "\n",
    "# Original Idendity of the Image\n",
    "ID_A = GEN_BA(IMG_A)\n",
    "ID_B = GEN_AB(IMG_B)\n",
    "\n",
    "# Discriminator Model shouldn't be affected during Adverserial(Combined Model) Optimization\n",
    "# So the discriminator model is frozen \n",
    "DCRM_A.trainable = False\n",
    "DCRM_B.trainable = False\n",
    "\n",
    "# Discriminator Confidence of Fake images\n",
    "CONF_FAKE_IMG_A = DCRM_A(FAKE_IMG_A)\n",
    "CONF_FAKE_IMG_B = DCRM_B(FAKE_IMG_B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Adverserial Net - Combined Network - Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The Combined model will calculate all this loss:\n",
    "1) Discriminator loss of generated image\n",
    "2) Reconstruction loss from generated image back to the original image\n",
    "3) Identity loss from original image to generated image\n",
    "\n",
    "This loss will be used to optimize the Generator Model\n",
    "'''\n",
    "COMBINED = Model([IMG_A, IMG_B],\n",
    "                [CONF_FAKE_IMG_A, CONF_FAKE_IMG_B,\n",
    "                 RECONSTRUCT_A, RECONSTRUCT_B,\n",
    "                 ID_A, ID_B])\n",
    "\n",
    "COMBINED.compile(loss= ['mse', 'mse',\n",
    "                        'mae', 'mae',\n",
    "                        'mae', 'mae'], \n",
    "                 loss_weights = [1, 1,\n",
    "                                 10.0, 10.0,\n",
    "                                 1.0, 1.0],\n",
    "                 optimizer = g_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities\n",
    "* Saving Model\n",
    "* Loading Model\n",
    "* Saving Log\n",
    "* Save Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Discriminator and Generator Models at Checkpoint Path\n",
    "def save_model():\n",
    "    global DCRM_A, DCRM_B, GEN_AB, GEN_BA\n",
    "    models = [DCRM_A, DCRM_B, GEN_AB, GEN_BA]\n",
    "    model_names = ['DCRM_A', 'DCRM_B', 'GEN_AB', 'GEN_BA']\n",
    "\n",
    "    for model, model_name in zip(models, model_names):\n",
    "        model_path =  CHECKPOINT + \"%s.json\" % model_name\n",
    "        weights_path = CHECKPOINT + \"/%s.hdf5\" % model_name\n",
    "        options = {\"file_arch\": model_path, \n",
    "                    \"file_weight\": weights_path}\n",
    "        json_string = model.to_json()\n",
    "        open(options['file_arch'], 'w').write(json_string)\n",
    "        model.save_weights(options['file_weight'])\n",
    "    print(\"Saved Model\")\n",
    "\n",
    "# Loading Discriminator and Generator Models from CHECKPOINT Path\n",
    "def load_model():\n",
    "    # Checking if all the model exists\n",
    "    model_names = ['DCRM_A', 'DCRM_B', 'GEN_AB', 'GEN_BA']\n",
    "    files = os.listdir(CHECKPOINT)\n",
    "    for model_name in model_names:\n",
    "        if model_name+\".json\" not in files or\\\n",
    "           model_name+\".hdf5\" not in files:\n",
    "            print(\"Models not Found\")\n",
    "            return\n",
    "    \n",
    "    global DCRM_A, DCRM_B, GEN_AB, GEN_BA, d_optimizer, d_loss\n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "    \n",
    "    # load DCRM_A Model\n",
    "    model_path = CHECKPOINT + \"%s.json\" % 'DCRM_A'\n",
    "    weight_path = CHECKPOINT + \"%s.hdf5\" % 'DCRM_A'\n",
    "    with open(model_path, 'r') as f:\n",
    "        DCRM_A = model_from_json(f.read())\n",
    "    DCRM_A.load_weights(weight_path)\n",
    "    DCRM_A.compile(loss=d_loss, optimizer=d_optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    # load DCRM_B Model\n",
    "    model_path = CHECKPOINT + \"%s.json\" % 'DCRM_B'\n",
    "    weight_path = CHECKPOINT + \"%s.hdf5\" % 'DCRM_B'\n",
    "    with open(model_path, 'r') as f:\n",
    "        DCRM_B = model_from_json(f.read())\n",
    "    DCRM_B.load_weights(weight_path)\n",
    "    DCRM_B.compile(loss=d_loss, optimizer=d_optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    # # load GEN_AB Model\n",
    "    model_path = CHECKPOINT + \"%s.json\" % 'GEN_AB'\n",
    "    weight_path = CHECKPOINT + \"%s.hdf5\" % 'GEN_AB' \n",
    "    with open(model_path, 'r') as f:\n",
    "        GEN_AB = model_from_json(f.read())\n",
    "    GEN_AB.load_weights(weight_path)\n",
    "\n",
    "    #load GEN_BA Model\n",
    "    model_path = CHECKPOINT + \"%s.json\" % 'GEN_BA'\n",
    "    weight_path = CHECKPOINT + \"%s.hdf5\" % 'GEN_BA'\n",
    "    with open(model_path, 'r') as f:\n",
    "         GEN_BA = model_from_json(f.read())\n",
    "    GEN_BA.load_weights(weight_path)\n",
    "        \n",
    "    print(\"Loaded Model\")\n",
    "\n",
    "# Saving log in LOG_PATH\n",
    "def save_log(log):\n",
    "    with open(LOG_PATH, 'a') as f:\n",
    "        f.write(\"%s\\n\" %log)\n",
    "    \n",
    "# Save images to SAVE_IMAGE directory\n",
    "#          #################################\n",
    "# img =    #IMG_A, FAKE_A, RECONSTRUCTED_A#\n",
    "#          #IMG_B, FAKE_B, RECONSTRUCTED_B#\n",
    "           ################################\n",
    "def save_image(epoch, steps):\n",
    "    TEST_DATA_A, TEST_DATA_B = data.get_data(1)\n",
    "    for i in range(TEST_DATA_A.shape[0]):\n",
    "        original_A = TEST_DATA_A[i]\n",
    "        original_B = TEST_DATA_B[i]\n",
    "        real_A = original_A / 127.5 - 1\n",
    "        real_B = original_B / 127.5 - 1\n",
    "        real_A = np.reshape(real_A, [1, real_A.shape[0], real_A.shape[1], real_A.shape[2]])\n",
    "        real_B = np.reshape(real_B, [1, real_B.shape[0], real_B.shape[1], real_B.shape[2]])\n",
    "        \n",
    "        fake_A = GEN_BA.predict(real_B)\n",
    "        fake_A = (fake_A + 1) * 127.5\n",
    "        fake_A = fake_A.astype(np.uint8)\n",
    "        fake_B = GEN_AB.predict(real_A)\n",
    "        fake_B = (fake_B + 1) * 127.5\n",
    "        fake_B = fake_B.astype(np.uint8)\n",
    "        \n",
    "        recon_A = GEN_BA.predict(fake_B)\n",
    "        recon_A = (recon_A + 1) * 127.5\n",
    "        recon_A = recon_A.astype(np.uint8)\n",
    "        recon_B = GEN_AB.predict(fake_A)\n",
    "        recon_B = (recon_B + 1) * 127.5\n",
    "        recon_B = recon_B.astype(np.uint8)\n",
    "        \n",
    "        image_1 = np.concatenate((original_A, fake_B[0], recon_A[0]), axis=1)\n",
    "        image_2 = np.concatenate((original_B, fake_A[0], recon_B[0]), axis=1)\n",
    "        image = np.concatenate((image_1, image_2), axis=0)\n",
    "        image_path = SAVED_IMAGES_PATH + \"_\".join([str(epoch), str(steps)]) + \".jpg\"\n",
    "        cv2.imwrite(image_path, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    start_time = datetime.now()\n",
    "    saved_time = start_time\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        steps = 1\n",
    "        while True:\n",
    "            \n",
    "            imgs_A, imgs_B = data.get_data(BATCH_SIZE)\n",
    "            \n",
    "            # If value is None it means it is out of data,\n",
    "            # it auto resets the data loader and breaks out of 'while' loop and starts as next batch\n",
    "            if imgs_A is None or imgs_B is None:\n",
    "                break\n",
    "            \n",
    "            # assign local batch_size \n",
    "            batch_size = imgs_A.shape[0]\n",
    "            \n",
    "            # Rescale the image value from 255 => -1 to 1\n",
    "            imgs_A = imgs_A / 127.5 - 1\n",
    "            imgs_B = imgs_B / 127.5 - 1\n",
    "            \n",
    "            # Discriminator Ground Truth\n",
    "            real = np.ones((batch_size,) + patch)\n",
    "            fake = np.zeros((batch_size,) + patch)\n",
    "            \n",
    "            # Train Discriminator\n",
    "            fake_A = GEN_BA.predict(imgs_B)\n",
    "            fake_B = GEN_AB.predict(imgs_A)\n",
    "            \n",
    "            dA_loss_real = DCRM_A.train_on_batch(imgs_A, real)\n",
    "            dA_loss_fake = DCRM_A.train_on_batch(fake_A, fake)\n",
    "            dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
    "            \n",
    "            dB_loss_real = DCRM_B.train_on_batch(imgs_B, real)\n",
    "            dB_loss_fake = DCRM_B.train_on_batch(fake_B, fake)\n",
    "            dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
    "            \n",
    "            d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
    "            \n",
    "            \n",
    "            # Train Generator\n",
    "            # Training the Generator twice as to catch up with the discriminator\n",
    "            for i in range(2):\n",
    "                g_loss = COMBINED.train_on_batch([imgs_A, imgs_B],\n",
    "                                                 [real, real,\n",
    "                                                  imgs_A, imgs_B,\n",
    "                                                  imgs_A, imgs_B])\n",
    "\n",
    "            \n",
    "            # Save Model\n",
    "            current_time = datetime.now()\n",
    "            difference_time = current_time - saved_time\n",
    "            if difference_time.seconds >= (TIME_INTERVALS * 60):\n",
    "                save_model()\n",
    "                save_image(epoch, steps)\n",
    "                saved_time = current_time\n",
    "            display(imgs_A, fake_A, imgs_B, fake_B)\n",
    "            \n",
    "            # Print and Save Log\n",
    "            log = \"Ep: %d, steps: %d, D loss: %f, acc: %3d%%, G loss: %f\" %(epoch,\n",
    "                                                                                steps, d_loss[0], 100*d_loss[1],\n",
    "                                                                                g_loss[0])\n",
    "            print(log)\n",
    "            save_log(log)\n",
    "            steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loads model if exist in Checkpoint Path\n",
    "load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
